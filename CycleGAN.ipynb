{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd2776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f2bed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foggy 10\n",
      "City 10\n"
     ]
    }
   ],
   "source": [
    "file_foggy = '/Users/boyang/Documents/projects/5469/5469project/data/training/foggy/*'\n",
    "file_city = '/Users/boyang/Documents/projects/5469/5469project/data/training/city/*'\n",
    "\n",
    "images_r = np.zeros(shape=(10,512,512,3))\n",
    "images_c = np.zeros(shape=(10,512,512,3))\n",
    "i=0\n",
    "image_paths = glob.glob(file_foggy)\n",
    "for file in image_paths:\n",
    "    img = cv2.cvtColor(cv2.imread(file), cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (512,512), interpolation = cv2.INTER_AREA)\n",
    "    img = np.array((img/127.5) - 1)\n",
    "    images_r[i] = img\n",
    "    i+=1\n",
    "    if i%10==0:\n",
    "        print(\"Foggy\", i)\n",
    "        break\n",
    "\n",
    "i=0        \n",
    "image_paths = sorted(glob.glob(file_city))\n",
    "for file in image_paths:\n",
    "    img = cv2.cvtColor(cv2.imread(file), cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (512,512), interpolation = cv2.INTER_AREA)\n",
    "    img = np.array((img/127.5) - 1)\n",
    "    images_c[i] = img\n",
    "    i+=1\n",
    "    if i%10==0:\n",
    "        print(\"City\", i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db088c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_X = images_r[:int(0.9*len(images_r))]\n",
    "test_X = images_r[int(0.9*len(images_r)):]\n",
    "train_y = images_c[:int(0.9*len(images_c))]\n",
    "test_y = images_c[int(0.9*len(images_c)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7e9e860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 11:37:56.049365: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-12-01 11:37:56.049549: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 128, 128, 64)      3136      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 128)       131200    \n",
      "                                                                 \n",
      " instance_normalization (Ins  (None, 64, 64, 128)      256       \n",
      " tanceNormalization)                                             \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 256)       524544    \n",
      "                                                                 \n",
      " instance_normalization_1 (I  (None, 32, 32, 256)      512       \n",
      " nstanceNormalization)                                           \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 512)       2097664   \n",
      "                                                                 \n",
      " instance_normalization_2 (I  (None, 16, 16, 512)      1024      \n",
      " nstanceNormalization)                                           \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 512)       4194816   \n",
      "                                                                 \n",
      " instance_normalization_3 (I  (None, 16, 16, 512)      1024      \n",
      " nstanceNormalization)                                           \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 1)         8193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,962,369\n",
      "Trainable params: 6,962,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# define the discriminator model\n",
    "def define_discriminator(image_shape):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # source image input\n",
    "    in_image = Input(shape=image_shape)\n",
    "    # C64\n",
    "    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C128\n",
    "    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C256\n",
    "    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # C512\n",
    "    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # second last output layer\n",
    "    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "    d = InstanceNormalization(axis=-1)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # patch output\n",
    "    patch_out = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "    # define model\n",
    "    model = Model(in_image, patch_out)\n",
    "    # compile model\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=0.0002, beta_1=0.5), loss_weights=[0.5])\n",
    "    return model\n",
    "# define image shape\n",
    "image_shape = (256,256,3)\n",
    "# create the model\n",
    "model = define_discriminator(image_shape)\n",
    "# summarize the model\n",
    "model.summary()\n",
    "# plot the model\n",
    "plot_model(model, to_file='discriminator_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d7af368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator a resnet block\n",
    "def resnet_block(n_filters, input_layer):\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # first layer convolutional layer\n",
    "    g = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(input_layer)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # second convolutional layer\n",
    "    g = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    # concatenate merge channel-wise with input layer\n",
    "    g = Concatenate()([g, input_layer])\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d681a33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 256, 256, 64  9472        ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " instance_normalization_4 (Inst  (None, 256, 256, 64  128        ['conv2d_6[0][0]']               \n",
      " anceNormalization)             )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 256, 256, 64  0           ['instance_normalization_4[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 128, 128, 12  73856       ['activation[0][0]']             \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " instance_normalization_5 (Inst  (None, 128, 128, 12  256        ['conv2d_7[0][0]']               \n",
      " anceNormalization)             8)                                                                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 128, 128, 12  0           ['instance_normalization_5[0][0]'\n",
      "                                8)                               ]                                \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 64, 64, 256)  295168      ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_6 (Inst  (None, 64, 64, 256)  512        ['conv2d_8[0][0]']               \n",
      " anceNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 64, 64, 256)  0           ['instance_normalization_6[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 64, 64, 256)  590080      ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_7 (Inst  (None, 64, 64, 256)  512        ['conv2d_9[0][0]']               \n",
      " anceNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 64, 64, 256)  0           ['instance_normalization_7[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_8 (Inst  (None, 64, 64, 256)  512        ['conv2d_10[0][0]']              \n",
      " anceNormalization)                                                                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 64, 64, 512)  0           ['instance_normalization_8[0][0]'\n",
      "                                                                 , 'activation_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " instance_normalization_9 (Inst  (None, 64, 64, 256)  512        ['conv2d_11[0][0]']              \n",
      " anceNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 64, 64, 256)  0           ['instance_normalization_9[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_10 (Ins  (None, 64, 64, 256)  512        ['conv2d_12[0][0]']              \n",
      " tanceNormalization)                                                                              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64, 64, 768)  0           ['instance_normalization_10[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 64, 64, 256)  1769728     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " instance_normalization_11 (Ins  (None, 64, 64, 256)  512        ['conv2d_13[0][0]']              \n",
      " tanceNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 64, 64, 256)  0           ['instance_normalization_11[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_12 (Ins  (None, 64, 64, 256)  512        ['conv2d_14[0][0]']              \n",
      " tanceNormalization)                                                                              \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 64, 64, 1024  0           ['instance_normalization_12[0][0]\n",
      "                                )                                ',                               \n",
      "                                                                  'concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 64, 64, 256)  2359552     ['concatenate_2[0][0]']          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " instance_normalization_13 (Ins  (None, 64, 64, 256)  512        ['conv2d_15[0][0]']              \n",
      " tanceNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 64, 64, 256)  0           ['instance_normalization_13[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_14 (Ins  (None, 64, 64, 256)  512        ['conv2d_16[0][0]']              \n",
      " tanceNormalization)                                                                              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 64, 64, 1280  0           ['instance_normalization_14[0][0]\n",
      "                                )                                ',                               \n",
      "                                                                  'concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 64, 64, 256)  2949376     ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " instance_normalization_15 (Ins  (None, 64, 64, 256)  512        ['conv2d_17[0][0]']              \n",
      " tanceNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 64, 64, 256)  0           ['instance_normalization_15[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_16 (Ins  (None, 64, 64, 256)  512        ['conv2d_18[0][0]']              \n",
      " tanceNormalization)                                                                              \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 64, 64, 1536  0           ['instance_normalization_16[0][0]\n",
      "                                )                                ',                               \n",
      "                                                                  'concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 64, 64, 256)  3539200     ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " instance_normalization_17 (Ins  (None, 64, 64, 256)  512        ['conv2d_19[0][0]']              \n",
      " tanceNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 64, 64, 256)  0           ['instance_normalization_17[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " instance_normalization_18 (Ins  (None, 64, 64, 256)  512        ['conv2d_20[0][0]']              \n",
      " tanceNormalization)                                                                              \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 64, 64, 1792  0           ['instance_normalization_18[0][0]\n",
      "                                )                                ',                               \n",
      "                                                                  'concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 128, 128, 12  2064512    ['concatenate_5[0][0]']          \n",
      " ose)                           8)                                                                \n",
      "                                                                                                  \n",
      " instance_normalization_19 (Ins  (None, 128, 128, 12  256        ['conv2d_transpose[0][0]']       \n",
      " tanceNormalization)            8)                                                                \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 128, 128, 12  0           ['instance_normalization_19[0][0]\n",
      "                                8)                               ']                               \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 256, 256, 64  73792      ['activation_9[0][0]']           \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " instance_normalization_20 (Ins  (None, 256, 256, 64  128        ['conv2d_transpose_1[0][0]']     \n",
      " tanceNormalization)            )                                                                 \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 256, 256, 64  0           ['instance_normalization_20[0][0]\n",
      "                                )                                ']                               \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 256, 256, 3)  9411        ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " instance_normalization_21 (Ins  (None, 256, 256, 3)  6          ['conv2d_21[0][0]']              \n",
      " tanceNormalization)                                                                              \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 256, 256, 3)  0           ['instance_normalization_21[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18,461,961\n",
      "Trainable params: 18,461,961\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(image_shape, n_resnet=6):\n",
    "  #  with strategy.scope():\n",
    "  # Everything that creates variables should be under the strategy scope.\n",
    "  # In general this is only model construction & `compile()`.\n",
    "  \n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # image input\n",
    "    in_image = Input(shape=image_shape)\n",
    "    # c7s1-64\n",
    "    g = Conv2D(64, (7,7), padding='same', kernel_initializer=init)(in_image)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # d128\n",
    "    g = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # d256\n",
    "    g = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # R256\n",
    "    for _ in range(n_resnet):\n",
    "        g = resnet_block(256, g)\n",
    "    # u128\n",
    "    g = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # u64\n",
    "    g = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    g = Activation('relu')(g)\n",
    "    # c7s1-3\n",
    "    g = Conv2D(3, (7,7), padding='same', kernel_initializer=init)(g)\n",
    "    g = InstanceNormalization(axis=-1)(g)\n",
    "    out_image = Activation('tanh')(g)\n",
    "    # define model\n",
    "    model = Model(in_image, out_image)\n",
    "    return model\n",
    "# define image shape\n",
    "image_shape = (256,256,3)\n",
    "# create the model\n",
    "model = define_generator(image_shape)\n",
    "# summarize the model\n",
    "model.summary()\n",
    "# plot the model\n",
    "plot_model(model, to_file='generator_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daa60399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a composite model for updating generators by adversarial and cycle loss\n",
    "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
    "    # ensure the model we're updating is trainable\n",
    "    g_model_1.trainable = True\n",
    "    # mark discriminator as not trainable\n",
    "    d_model.trainable = False\n",
    "    # mark other generator model as not trainable\n",
    "    g_model_2.trainable = False\n",
    "    # discriminator element\n",
    "    input_gen = Input(shape=image_shape)\n",
    "    gen1_out = g_model_1(input_gen)\n",
    "    output_d = d_model(gen1_out)\n",
    "    # identity element\n",
    "    input_id = Input(shape=image_shape)\n",
    "    output_id = g_model_1(input_id)\n",
    "    # forward cycle\n",
    "    output_f = g_model_2(gen1_out)\n",
    "    # backward cycle\n",
    "    gen2_out = g_model_2(input_id)\n",
    "    output_b = g_model_1(gen2_out)\n",
    "    # define model graph\n",
    "    model = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
    "    # define optimization algorithm configuration\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    # compile model with weighting of least squares loss and L1 loss\n",
    "    model.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdb4f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape\n",
    "image_shape = (512,512,3)\n",
    "# generator: A -> B\n",
    "g_model_AtoB = define_generator(image_shape)\n",
    "# generator: B -> A\n",
    "g_model_BtoA = define_generator(image_shape)\n",
    "# discriminator: A -> [real/fake]\n",
    "d_model_A = define_discriminator(image_shape)\n",
    "# discriminator: B -> [real/fake]\n",
    "d_model_B = define_discriminator(image_shape)\n",
    "# composite: A -> B -> [real/fake, A]\n",
    "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
    "# composite: B -> A -> [real/fake, B]\n",
    "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a64679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "    # choose random instances\n",
    "    ix = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "    # retrieve selected images\n",
    "    X = dataset[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = np.ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, dataset, patch_shape):\n",
    "    # generate fake instance\n",
    "    X = g_model.predict(dataset)\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    display_list = [dataset[0], X[0]]\n",
    "    title = ['Input Image', 'Predicted Image']\n",
    "\n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.title(title[i])\n",
    "        # getting the pixel values between [0, 1] to plot it.\n",
    "        plt.imshow((display_list[i] + 1) * 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "            \n",
    "    # create 'fake' class labels (0)\n",
    "    y = np.zeros((len(X), patch_shape, patch_shape, 1))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# select a batch of real samples\n",
    "# X_realA, y_realA = generate_real_samples(train_X, 1, 24)\n",
    "# X_realB, y_realB = generate_real_samples(train_y, 1, 24)\n",
    "\n",
    "# # generate a batch of fake samples\n",
    "# X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, 24)\n",
    "# X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e61c83f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update image pool for fake images\n",
    "def update_image_pool(pool, images, max_size=50):\n",
    "    selected = list()\n",
    "    for image in images:\n",
    "        if len(pool) < max_size:\n",
    "            # stock the pool\n",
    "            pool.append(image)\n",
    "            selected.append(image)\n",
    "        elif np.random.random() < 0.5:\n",
    "            # use image, but don't add it to the pool\n",
    "            selected.append(image)\n",
    "        else:\n",
    "            # replace an existing image and use replaced image\n",
    "            ix = np.random.randint(0, len(pool))\n",
    "            selected.append(pool[ix])\n",
    "            pool[ix] = image\n",
    "    return np.asarray(selected)\n",
    "\n",
    "# update fakes from pool\n",
    "#X_fakeA = update_image_pool(poolA, X_fakeA)\n",
    "#X_fakeB = update_image_pool(poolB, X_fakeB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6201c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function for the cyclegan models\n",
    "def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, trainA,trainB):\n",
    "\n",
    "  # define properties of the training run\n",
    "  n_epochs, n_batch, = 10, 1 #Keep n_batch as 1 for per image training. n_epochs can be changed\n",
    "  # determine the output square shape of the discriminator\n",
    "  n_patch = d_model_A.output_shape[1] #Notice n_patch depends on the discriminator output image size. This parameter can be changed for improvement.\n",
    "  \n",
    "  # prepare image pool for fakes\n",
    "  poolA, poolB = list(), list()\n",
    "  # calculate the number of batches per training epoch\n",
    "  bat_per_epo = int(len(trainA) / n_batch)\n",
    "  # calculate the number of training iterations\n",
    "  n_steps = bat_per_epo * n_epochs\n",
    "  # manually enumerate epochs\n",
    "  print(n_steps)\n",
    "  for i in range(n_steps):\n",
    "  # select a batch of real samples\n",
    "    X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
    "    X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
    "    \n",
    "    # generate a batch of fake samples\n",
    "    X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
    "    X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
    "    # update fakes from pool\n",
    "    X_fakeA = update_image_pool(poolA, X_fakeA)\n",
    "    X_fakeB = update_image_pool(poolB, X_fakeB)\n",
    "    # update generator B->A via adversarial and cycle loss\n",
    "    g_loss2, _, _, _, _ = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n",
    "    # update discriminator for A -> [real/fake]\n",
    "    dA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
    "    dA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
    "    # update generator A->B via adversarial and cycle loss\n",
    "    g_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n",
    "    # update discriminator for B -> [real/fake]\n",
    "    dB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
    "    dB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
    "    # summarize performance\n",
    "    print('>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))\n",
    "  return(g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa08717",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load a dataset as a list of two numpy arrays\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainA \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_X\u001b[49m\n\u001b[1;32m      3\u001b[0m trainB \u001b[38;5;241m=\u001b[39m train_y\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# train models\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "# load a dataset as a list of two numpy arrays\n",
    "trainA = train_X\n",
    "trainB = train_y\n",
    "# train models\n",
    "train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, trainA, trainB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c04637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "g_model_AtoB.save('g_model_AtoB.hdf5')\n",
    "g_model_BtoA.save('g_model_BtoA.hdf5')\n",
    "c_model_AtoB.save('c_model_AtoB.hdf5')\n",
    "c_model_BtoA.save('c_model_BtoA.hdf5')\n",
    "\n",
    "g_model_AtoB = load_model('g_model_AtoB.hdf5')\n",
    "g_model_BtoA = load_model('g_model_BtoA.hdf5')\n",
    "c_model_AtoB = load_model('c_model_AtoB.hdf5')\n",
    "c_model_BtoA = load_model('c_model_BtoA.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4441897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "\n",
    "#write a function to generate 'n_samples' random integers in range (start,stop)\n",
    "def randnums(start,stop,n_samples):\n",
    "  ix=[]\n",
    "  for i in range(n_samples):\n",
    "    ix.append(randint(start,stop))\n",
    "  ix=np.array(ix)\n",
    "  return ix\n",
    "\n",
    "def test(g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, trainA,trainB):\n",
    "###################START CODE HERE#############################\n",
    "  X_realA=trainA[randnums(0, trainA.shape[0]-1, 1)]\n",
    "  X_fakeB=g_model_AtoB.predict(X_realA)\n",
    "  X_realB=trainB[randnums(0, trainB.shape[0]-1, 1)]\n",
    "  X_fakeA=g_model_BtoA.predict(X_realB)\n",
    "###############################################################    \n",
    "  ########First A to B transformation\n",
    "  print('Original A Image is=\\n')\n",
    "  plt.imshow(np.squeeze(X_realA))\n",
    "  plt.show()\n",
    "  print('Fake B image is=\\n')\n",
    "  plt.imshow(np.squeeze(X_fakeB))\n",
    "  plt.show()\n",
    "  #############Next B to A transformation\n",
    "  print('Original B Image is=\\n')\n",
    "  plt.imshow(np.squeeze(X_realB))\n",
    "  plt.show()\n",
    "  print('Fake A image is=\\n')\n",
    "  plt.imshow(np.squeeze(X_fakeA))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d90565f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m##Calling the test function here\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtest\u001b[49m(g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, trainA,trainB)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "##Calling the test function here\n",
    "test(g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, trainA,trainB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01b11cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import mean_squared_error as mse, structural_similarity as ssim\n",
    "#Function to compute similarity in Cycle images\n",
    "def similarity_real_fake(real,fake):\n",
    "  m = mse(real, fake)\n",
    "  s = ssim(np.squeeze(real), np.squeeze(fake), multichannel=True)\n",
    "  print('Original Image is=\\n')\n",
    "  plt.suptitle(\"MSE: %.2f, SSIM: %.2f\" % (m, s))\n",
    "  plt.imshow(np.squeeze(real))\n",
    "  plt.show()\n",
    "  print('Fake image is=\\n')\n",
    "  plt.imshow(np.squeeze(fake))\n",
    "  plt.show()\n",
    "\n",
    "def test_Cycle(g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, trainA,trainB):\n",
    "\n",
    "  # writting this function to call the similarity_real_fake function above and print it under each real->Generated image pair\n",
    "  print('A->B->A full cycle\\n')\n",
    "  for i in range(3):\n",
    "    X_realA=trainA[randnums(0, trainA.shape[0]-1, 1)]\n",
    "    X_fakeB=g_model_AtoB.predict(X_realA)\n",
    "    X_fakeA=g_model_BtoA.predict(X_fakeB)\n",
    "    similarity_real_fake(X_realA,X_fakeA)\n",
    "\n",
    "  print('B->A->B full cycle\\n')\n",
    "  for i in range(3):\n",
    "    X_realB=trainB[randnums(0, trainA.shape[0]-1, 1)]\n",
    "    X_fakeA=g_model_AtoB.predict(X_realB)\n",
    "    X_fakeB=g_model_BtoA.predict(X_fakeA)\n",
    "    similarity_real_fake(X_realB,X_fakeB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e22c1283",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_Cycle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calling the function test_Cycle(....)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtest_Cycle\u001b[49m(g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, trainA,trainB)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_Cycle' is not defined"
     ]
    }
   ],
   "source": [
    "# Calling the function test_Cycle(....)\n",
    "test_Cycle(g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, trainA,trainB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33054d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
